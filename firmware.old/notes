Stated explicitly:
    Make silicon do as much as possible - as few and as cheap external components as possible
        So avoid external DAC (expensive), use weighted resistor DAC
            unless VGA and NTSC look terrible, then upgrade to real DACs.
            unless real DAC would be cheaper than resistor DAC...
        But use external crystal if necessary to get color response from 1084 (and other monitors)
        Settle on STM32H743IIT6 for now
    App and Driver API should be the one you're most comfortable with (because no one else will use it!)
        But write something nice enough that someone else *could* use it.
    C++17 interfaces internally
    Windowing, then Processes (and pipes? signals?), then Loader

Modularizing video
    Get all video functions out into separate .cpps
        video mode drivers in their own files
        the thing that fills in NTSC's raw buffer and manages mouse events and windowing in its own file
        STM-specific implementation of DMA, etc in separate file and call the NTSC raw buffer goop - callback?
    Abstraction 
        drivers register themselves in a constructor function
            VideoSubSystem* NTSCVideoRegisterMode(VideoModeDriver *mode);
                 video subsystem keeps an array of these modes
        The platform initializes the video subsystem
            NTSCVideoStart or VGAVideoStart or HDMIVideoStart
                set up DAC?
                set up interrupts?
                    Need generic DMA interrupt to call Video-specific callback
                manage VRAM
            0 windows to start
                Maybe all video modes have a background color?  
            Maybe hardcoded shell opens a text window
            main loop routes events to video - VideoSubsystem->routeEvent(EventBase *event)
            VideoSubsystem draws window decorations (may want to share these among implementations)
        An app calls
            void VideoSetBackgroundColor(float r, float g, float b);
            VideoGetModeCount() to get number of modes, then loops through them
                VideoSubsystem has vector of VideoModeDriver*
            VideoModeGetType(int n) to get mode
                VideoSubsystem calls VideoModeDriver->getType();
            Status VideoModeGetInfo(int n, ModeInformation* info) to determine if it meets needs (or skip this)
            window = WindowCreate(mode, parameters)
                VideoSubsystem:
                    checks
            while((status = EventPoll(&event)) {
                switch(event.type) (
                    ...
                }
            }

Getting to color - Duplicate other signal timing & voltages as closely as possible, including # of colorbursts
    VCR, barring that, Apple //e, NES?, DVD?
    Make nice diagrams of a single frame's signal
    Hm, can CB be per-line?

Measured MCO/5 as HSE at 4.00086MHz on freq counter, so 20MHz crystal is giving me 20.00430 Mhz

Use RGB LEDs thusly:
    During Boot
    While Running
        LED1 increases in brightness with average CPU spend in scanline; last 10% shown in red
            Panic - cycle red on-off every half-second
        LED2 lit when SD being accessed
        LED3 set by top-most application
Could probably pull off 304x192 r5g6b5 framebuffer within 128K, or 384x256 r3g3b2 within 128K (would dither)
    But why bother with r3g3b2?  Just make a 256-LUT?  Save memory, make conversion explicit?
Close on segmented framebuffer
    textured and solid triangles, trapezoids, and segments
    need a way to merge or continue runs to reduce memory usage
    teapot with Enable(CULLFACE):
        max 75 segments in one row
        max 8756 segments in frame
        max 41976 trapezoids per frame
    polytope256 with Enable(CULLFACE):
        max 62 segments in one row
        max 11426 segments in frame
        max 64728 trapezoids
New Video API
    NTSC needs to either be filled with "phase" (column % 4) to get the waveform right, or always aligned to 4 clocks
    Video Subsystem keeps track of window location, size, order in stacking, whether it's fullscreen, and its mode
    How are text windows created?  rows and columns? - separate API?
    How are fullscreen-only windows created?  rows and columns? - separate API?
    Does every viedo mode have a debug overlay?
    Application API exposed by video subsystem:
        int VideoGetModeCount();
        enum VideoModeType VideoModeGetType(int n);
        struct ModeInformation {
            VideoModeType type;
        };
        Status VideoModeGetInfo(int n, ModeInformation* info) to determine if it meets needs (or skip this)
            What does this actually do in the new API?
            pixel aspect ratio
            pixmap: isMonochrome, paletteSize, pixmapFormat
        enum WindowParameter { END = 0, PREFERRED_SIZE = 1 /* w, h */, GET_SIZE_OR_FAIL = 2, FULLSCREEN_OVERSCAN = 3, FULLSCREEN_UNDERSCAN = 4};
        int WindowCreate(int mode, int *parameters);
            -> always produces "RESIZE" and "REDRAW" events - get width and height that way
            Subsequent moves and stack order changes *might* not REDRAW - the system could decide to keep a backing-store of the image.
            position and size may be selected by mouse
                if not fullscreen, moust selects window position
                if window mode !isFixedSize, mouse rubberbands window size, modulated to getNearestNotLarger()
        void WindowClose(int window);
        Mode specific functions. These can return INVALID_CALL_FOR_MODE.
            Status WindowSetPaletteEntry(int window, int palette, int which, float r, float g, float b);
            Status WindowSetPalette(int window, int palette, float *rgbEntries);
            Status WindowSetRowPalette(int window, int row, int palette);
        Old API:
            int VideoGetModeCount() -> no change
            enum VideoModeType VideoModeGetType(int n) -> no change
            void VideoModeGetInfo(int n, void *info) -> goes away
            void VideoSetMode(int n) -> goes away, implicit in window
            int VideoGetCurrentMode() -> goes away, implicit in window
            void VideoModeGetParameters(void *params) -> VideoModeGetParameters()
            void VideoModeWaitEndFrame() -> no signature change but Block until the beginning of VBLANK / VSYNC
            Status VideoModeSetPaletteEntry(int palette, int which, float r, float g, float b)
                can return INVALID_CALL_FOR_MODE
            Status VideoModeSetRowPalette(int row, int palette)
                can return INVALID_CALL_FOR_MODE
    API that video driver implements:
        struct ScanlineSpan { int start; int length; };
        struct WindowSpanList { int start; int count; struct ScanlineSpan *spans };
        struct VideoWindowDescriptor { void* vram; uint32_t rootOffset; };
        API that video subsystem implements for drivers:
            typedef uint32_t (*VideoSubsystemAllocateFunc)(size_t size); - offset from base VRAM pointer, wherever that is
        enum VideoModeType that already exists
        struct VideoModeDriver {
            // a class can exist with no members and only virtual functions, but maybe should add name
            // How are special extra methods exposed?
            // like all draw funcs (text vs wolfenstein vs pixmap/colortable vs segments)
            VideoModeType getModeType();
            virtual bool isFixedSize() = 0; // fixed size, e.g. TMS9918A or Woz or Channel F, NTSC knows that if this gives minimum Size 704x460, this mode is fullscreen overscan only
            virtual bool getMinimumSize(int *w, int *h) = 0; // if a fixed size, put fixed dimensions in these 
            virtual bool getNearestNotLarger(int w, int h, int *nearestNotLargerW, int *nearestNotLargerH) = 0; // mostly for text modes - only succeed for multiples of text size, put nearest smaller window size in W and H (for outline during resizing)
            virtual bool reallocateForWindow(int windowSpanCount, struct WindowSpanList* windowSpans, const VideoWindowDescriptor* oldWindow, void* vramTemp, uint32_t *rootOffset, VideoSubsystemAllocateFunc allocate, bool copyContents) = 0;
                allocates per-scanline or per-window as necessary, keeps track of its own kind of allocation
                might make a per-window allocation e.g. colormap
                allocate a "root" buffer containing additional allocations and store root buffer in rootOffset
                    e.g. color tables and then scanline data for pixmaps
                    or window + windowspans
                    or allocate one big buffer and carve everything up in there e.g. text?, TMS9918, Wolfenstein
                copy old allocations from vram to new allocations in vramTemp if copyContents
                    e.g. color tables, but leave scanline pixmap regions junk or 0
                    e.g. copy text because all text kept around?
                    e.g. copy TMS9918 data or Wolfenstein data or segments
                if !copyContents, then window system is probably trying to resize or create a new window and testing a layout.
                if copyContents and all windows succeed, then rootOffsets will be changed and vramTemp will be copied to vram as quickly as possibly during VBLANK
                therefore no pointers within VRAM, only offsets
                if vram is nullptr and oldOffset is 0xFFFFFFFF, then window didn't exist before
        }
        struct NTSCModeDriver : public VideoModeDriver
        {
            virtual void fill(const VideoWindowDescriptor* window, int columnStartOnScreen /* for color phase */, int screenRow /* for flipping ColorBurst */, int columnStartWithinWindow, int pixelCount, int rowWithinWindow, unsigned char *rowData) = 0;
            // debug version could put rowData somewhere else, check it for corrupting nearby data, then copy it when done
        }
        640 * 384 is a good underscan mode
        704 * 460 is a good overscan mode
        struct PixmapModeInformation
        {
            VideoModeType type;
            bool isMonochrome; // Only used by NTSC Video Subsystem to determine whether to do Colorburst
            enum PixmapFormat { PIXMAP_1BIT, PIXMAP_2BIT, PIXMAP_4BIT, PIXMAP_8BIT } pixmapFormat;
            enum PaletteSize { PALETTE_4_ENTRIES, PALETTE_16_ENTRIES, PALETTE_256_ENTRIES } paletteSize;
        };
        struct PixmapMode : public VideoModeDriver
        {
            Let's say maximum resolution, 704x460; can get 2 bits per pixel in that mode in roughly 112KB.
            Let's say 1 byte per pixel. can easily do 384 * 230 in that mode in roughly 112KB.
            virtual void getInfo(PixmapModeInformation* info) = 0;
            enum PaletteIndex { PALETTE0, PALETTE1 };
            virtual void setPaletteContents(const VideoWindowDescriptor* window, PaletteIndex which, unsigned char (*palette)[3]) = 0;
            virtual void setRowPalette(const VideoWindowDescriptor* window, int row, PaletteIndex which) = 0;
            virtual void drawPixelRect(const VideoWindowDescriptor* window, int left, int top, int width, int height, size_t rowBytes, unsigned char *pixmap) = 0; // packed like pixel format
            // Need more drawing functions here - this has essentially made the framebuffer opaque
        };
        struct TextportMode : public VideoModeDriver
        {
            virtual void setCursorPosition(const VideoWindowDescriptor* window, int col, int row) = 0;
            virtual void setCursorAttributes(const VideoWindowDescriptor* window, uint32_t attributes) = 0;
            virtual void clearArea(const VideoWindowDescriptor* window, int col, int row, int cols, int rows) = 0;
            virtual void drawChar(const VideoWindowDescriptor* window, int col, int row, char c) = 0;
            virtual void copyArea(const VideoWindowDescriptor* window, int col, int row, int cols, int rows, int newcol, int newrow) = 0;
            virtual void drawArea(const VideoWindowDescriptor* window, int col, int row, int cols, int rows, const char *text) = 0;
        }
        struct SegmentVideoMode : public VideoModeDriver
        {
            virtual int setScanlineSegments(const VideoWindowDescriptor* window, int scanlineCount, const VideoSegmentedScanline *scanlines) = 0; // but this is variable size?  maybe there can only ever be one of these and its reallocated last and allocates as much as it can.
        }
        struct WolfensteinMode : public VideoModeDriver
        {
            virtual void setElements(const VideoWindowDescriptor* window, const VideoWolfensteinElement* elements) = 0;
        }
        struct DCTVideoMode : public VideoModeDriver
        {
        }
        struct WozVideoMode : public VideoModeDriver
        {
        }
        struct TMS9918AMode : public VideoModeDriver
        {
        }
        struct VESVideoMode : public VideoModeDriver
        {
        }
    API that video subsystem implements for system:
        struct VideoSubsystemDriver {
            static VideoSubsystemDriver* start(); // NTSC system makes runtime constants, starts scanout
            virtual void stop() = 0;
            virtual void setDebugRow(int row, const char *rowText) = 0; // system sets debug information
        };
    re-allocation events: window stacking order changed, window moved, window resized, window fullscreened or windowed
        for every window
            make span list
            call allocate to video mode for window
            if failed, flash screen, maybe debug overlay, and exit re-allocation
        CommitAllocations
    int EventGet(Event *event);
    void MouseGetPosition(int *x, int *y);
    void MouseGetButtonsPressed(int *b1, int *b2, int *b2); // 0 = not pressed, 1 = pressed
    struct Event {
        enum { MOUSEMOVE, MOUSEBUTTONPRESS, MOUSEBUTTONRELEASE, RAWKEYBOARD, RESIZE, FULLSCREEN, WINDOWED, FRONT, BEHIND, REDRAW } eventType;
        union {
            struct MouseMoveEvent {
                int dx, dy;
            } mouseMove;
            struct MouseButtonPressEvent {
                int button;
            } mouseButtonPress;
            struct MouseButtonReleaseEvent {
                int button;
            } mouseButtonRelease;
            struct RawKeyboardEvent {
                int keycode;
            } rawKeyboard;
            struct ResizeEvent {
                int width, height;
            } resize;
            struct RedrawEvent {
                int left, top, width, height;
            } redraw;
            uint8_t reserved[64];
        };
    };
    every window (only front window?) has a 2 or 4-pixel border
    every scanline effectively needs a list of pixel ranges owned by windows - this should be in VRAM for DMA decoupling
    every window needs to be able to allocate only memory for storage for its ranges per row.
	could memory allocation and populating memory and calling expansion to video stream pixels be decoupled from the video mode?
            Wolf, DCT, 9918, Text, aren't specific to a scan line specific
    need a video mode which is a solid color for background
    Some video game modes (TMS9918A, Woz, TIA) require full-screen.
        Debug overlay says "Game mode" if ALT-space pressed or some such?
        Wolfenstein, too?  Not clear.
    all video modes can be windowed, but front can be fullscreen
        stop offering out pointers to memory, use Set-style functions for all content
        is fullscreen just a window that's full-screen size?  Or does it mean something else?
            wouldn't have border in fullscreen
            all memory can be dedicated to fullscreen and minimal book-keeping used
    Because NTSC has BW and Color modes, FRONT window dictates in NTSC whether Colorburst is added
    Win+Up to fullscreen FRONT window, Win+Down to return to previous size
    Click on not-FRONT window brings to FRONT
    Click on FRONT window is passed to app owning FRONT
    non-FRONT window doesn't get mouse moves?
    Click on border resizes (just outline is shown until button release)
    transparent backing-store mode from non-VRAM
        hooks the event functions and the Set-style functions
        catches REDRAW etc events, updates from backing-store when possible
        passes on to app if necessary (RESIZE, FULLSCREEN, REDRAW)
Move Wolf to palette-RGB-style textures (reduce bandwidth to make up lookup & process cost?)
honor aspect ratio in "show"
Some things to improve in "show"
    [--gray] - use a grayscale palette
    fix skipped lines in "hosted" - img lower resolution than framebuffer
    antialias
Make circle renderer find pixel center coordinates to see if the weird jumpiness is being caused by integer snapping - can't expect decent lit or textured rendering if the coordinates are going to jump around for some reason
DB-9 Coleco game controller
PS/2 keyboard and mouse
paletteToWave and rowPalette should be carved from imgBuffer so imgBuffer for non-palette modes has more space
    VRAMalloc
Some things to improve living
    textport should be virtual and overlaid on screen in text mode and preserved for returning to text mode
        so then textport output would ALWAYS work and be recorded, and switching back to text would restore the old viewport.
        40 vs 80?  - just always 80?  (Could maybe get to 106x60 chars with 5x7 wide at 480p)
        make a scrollback buffer (what are the keyboard controls to scroll back?)
        3 pages of 80x24 = 5760 bytes, need to keep in RAM somewhere
    Factor out shell
        tab should autocomplete at CLI
            tab in first completes commands
            tab in second et al completes filenames
    system button kicks back to text 0?
        or at least pops textport while button is down
        need a way to interrupt
        need a way to cancel and return from apps - longjmp?
    frame stats should be a histogram
        get TIM frequency nailed down
    serial and keyboard should interrupt and fill one buffer
    image viewer should add together lines and pixels so data is antialiased
Potential improvements
    use SDMMC peripheral
    There really should be a non-interlaced video mode
DCT video mode - make it so JPG blocks can be the source of the video scanout
MP3 player - target something simple and straightforward, like 128, 160, and 256 constant bitrate joint-stereo.
hosted
    No separate console access, e.g. serial port; operate like standalone machine
    CLI/apps in other thread
        queues for output chars...?
        video and audio calls take a lock
        video scanout happens 30 Hz and also takes the lock
Video API notes
    Fundamentally, CCMRAM lacks the memory for more than 1 byte per pixel at more than 250x200
        VideoMode has internals that convert to the display specifics
        VideoMode is the abstraction hiding the memory limitations from the application.
            Platform libraries do additional useful work, like converting R8G8B8 rows to 256-entry palettized images with Floyd-Steinberg
        Carve out 128K from 320K in 746, could easily have 512 * 240 * 256 colors
        Larger chip with 512K, could spare 256K, yield 640x400
        ** BUT part of the *novelty* of the project is that video is generated at a higher resolution than RAM allows. **
            e.g. very small palettes - 1, 2, 4 bit; RLE; DCT; specialized renderer (e.g. Wolfenstein, spin)
    NTSC output is by necessity Waves (DAC samples represent NTSC waveform at 14.31818 MHZ)
        Probably not much point in having R8G8B8 at 912 pixels per row - can't be represented
        So need to filter at least chroma down to 3.58MHz - Gaussian of 5 samples?  Could do box filter for start
            yiq can range from 
        Individual VideoModes could filter, or just the ones I care about could filter
        SET_AND_INCREMENT_WAVE(y, i, q)
    Commit to 565 for VGA output, use 3 DACs (and a whole 16-bit port?  Yikes!)
        *might* be able to convert 332 to FS-dithered at scan time
        Hook up to Parallax 332 DAC to start (and maybe dither), create 565 DAC later
    HDMI can be whatever as long as I have 3 bytes of RGB to look up in a table
clean up rect mode
setup a software interrupt for VBlank processing (e.g. update scanout stats, audio goop) and trigger it from row=262 and row = 525 -> event interrupt?
help and other output should be paged -
    have a special mode in non-VT102 mode?  Start Paging / Stop Paging?
    OutputSetPaging(int paging)
Move NTSC goop to another .c
Move Audio goop to another .c
Add some things to shell
    startup.sh # run from disk, quit scripting on blue button
    # run from a file
        will recursion work the way you've set it up?
    # parse between "" as one word
    # break commands on ";" outside ""
    # ignore everything after '#' outside ""
    sleep floatseconds # easy
    # variables - "$var"?
    menu var menufile # show a menu, return the option chosen in var
    getchar [var] # get a single character
    read [var] # get everything up to ENTER
    echo everything afterwards is echoed # easy
    # pixmap only :
        palette N r g b
        circle N x y r
        line N x0 y0 x1 y1
        clear N
    # expressions
    for var = A to B [step C] ; ... ; end
    for var in A B C D E F G ; ... ; end
VideoModeGetInfo should take a type so it can avoid copying wrong struct
everything should return 0 on success or non-zero error or void if it can't fail
audio
    22050Hz?  11025Hz?  8000Hz?
    write audio sample immediately on entry to line ISR?  Then calculate next one right after that, then do video calculation?
        Then audio resampling would happen at the line rate for whatever video mode is current...
    Do DMA at 22050 from double-buffered 512-byte buffers?  Could conflict with video but should be able to set priority lower.
    stereo audio output?
    audio modes:
        MIXED: add a finite-length U8 with arbitrary sample rate to the stream, audio processing will add up all active ones
        DIRECT: app callback to fill a buffer at a rate given to the callback
    does there need to be a mix in the DIRECT mode for things like beep, etc?
vile sucks, figure it out or replace it; issues:
    #dd doesn't work
    O and o behave weirdly
    0 does not go to the beginning of the line
    a and then enter does not scroll down
    #G uses line numbers off by one - is this termios?
VT102 handling (in combination with vile) doesn't handle inserting a line?
would be nice if video modes could have multiple submodes
    pixmap *and* text for last 4 rows
    wolfenstein *and* pixmap for bottom stats *and* upper-left small pixmap or text for FPS
special segment mode - 320 pixels wide (so 640 clocks, 2 clocks wide)
    app
        transforms lit, gouraud triangles to screen
        intersect scanlines with triangles
            output list of scanline edges
            do intersection and clipping of edges in depth
            sort in X including background
    video mode
        walks segments in turn assuming they touch all pixels
        interpolating, what?  RGB probably too slow - HSV?
        test program = circle
    Look up texture?  May be too hard to do perspective correction?
Should debug overlay XOR or just have black background?
    find pixel under and set white or black based on that?
Get DB9 joystick working
    uint32_t InputGetJoystickDir(int whichJoy) // flags or'd ; JOYSTICK_LEFT, etc
    uint32_t InputGetJoystickButton(int whichJoy) // flags or'd ; JOYSTICK_BUTTON0, JOYSTICK_BUTTON1, etc
    get Coleco joystick working
Raycaster game!
    monsters come after you, can be shot, inflict damage within certain range
    need sprites for powerups, monsters other goop
    gun
    bottom row shows health, points
    health powerups?
    put texture on ceiling and floor
video needs a "switching" mode
    old mode -> blank (fillrow does black) -> new mode
PS/2 mouse?
"Apps"
    Threading? (multitasking, task switching)
        all system functions have to be thread-safe...  Wrap locks around them
        then need scheduler
        if multiple apps can run simultaneously, then pipes would work
    run as emulated THUMB or QEMU in hosted
    compile all apps with TinyCC if possible - C++ preprocessor?
    Could a version of g++ or clang fit in 16MB?
    System APIs that Apps can call
        OS/stdlib calls
            read/write
            malloc, free, etc
            fopen, fclose, etc
        video mode and config (NTSC vs VGA handled by hard board switch)
        serial port control
        register vblank handler
        get time and sleep
        audio mode and config
        get keyboard input
        read DB9 joystick
        layered facilities
            textport
            VT102 terminal processing (on textport)
                essentially just init() and putchar()
            graphics routines
    terminal
    Wolfenstein
    3D viewer
    BASIC
    movie player... ? Targeted to full-screen 8-bit pixmap?  palette per frame?
    CP/M emulation
    Colecovision
    Apple2e
    WeFAX decoder
Additional video modes
    TMS 9918A mode - expose the chip I/O
        TMS pixels area is 192 lines high
    Apple //e mode - give pointers to memory and soft switches
    DCT mode
    scanline edge rendered mode - make RGB-to-byte as fast as possible
Channel F emulator, 9pin header adapters (bake into controller for Bart)
    need 16 pins for two controllers!
Some kind of 3D uberdemo, realtime scan out, buffer of sorted scanline segments?
BASIC
    just implement 80x24 text mode for now
    video N # set video mode N
    lut c, r, g, b # calculate lut entry c for int r, g, b
    plot x, y, c    # plot pixel x, y with lut c
    line x0, y0, x1, y1, c # plot line
    clear c # clear screen to LUT color
    text N # text mode
    split {0,1} # split screen graphics and text (dependent on the modes?)
    handle a bunch of old BASIC programs like STARTREK, WUMPUS, ...?
    implement lunar lander
    Life: https://www.atariarchives.org/basicgames/showpage.php?page=100
        https://github.com/rricharz/R65/blob/master/Basic/life.bas
    Lunar Lander: https://www.atariarchives.org/basicgames/showpage.php?page=106
        http://vintage-basic.net/bcg/lunar.bas
    Sine Wave: https://www.atariarchives.org/basicgames/showpage.php?page=146
        http://www.vintage-basic.net/bcg/sinewave.bas
    Super Star Trek: https://www.atariarchives.org/basicgames/showpage.php?page=157
    3D Plot: https://www.atariarchives.org/basicgames/showpage.php?page=167
        http://vintage-basic.net/bcg/3dplot.bas

4/13
    On a hunch that maybe AHB doesn't do uchar writes directly and
      instead fetched a long, masked, or'd, and wrote a long, I tried
      doing word writes to GPIOC->ODR from DMA.  This would
      have been very inconvenient (altering ALL of GPIOC at once) but
      also would have meant using much more memory (a uint32_t per
      sample even though only 8 bits are used).  It didn't help, and
      in fact seemed worse.  Color didn't lock, jitter seemed as
      bad as uchar, and fillRowBuffer took MUCH longer (like 50% of the ISR).
    Tried half transfer and circular DMA buffer instead of DBM.  No
      change.  I think this is expected - DBM and Circular are probably
      implemented with the same logic except Circular updates always
      from M0AR.
4/12
    Observations
        While playing the khan segment, I got 7 FIFO underruns.  But that was over the course of many seconds.
        Do I just have an electrical issue?  Like when enough of the chip fires at once, I get a brownout?
	    That would explain the noise while the CPU is operating.
	    The noise is just brightness variations and not loss of pixels or sync.

4/11
    VTOR - vector table TBLOFF
    putting VTOR in SRAM1 didn't do anything
    while(1) WFI nor WFE did anything

4/10
    observations
        Here's a mystery: the porch value is 0x50, and that's at one voltage.  If I fill the color image with 0x50, that shows a slightly different voltage.

4/9
    observations
        glitch happens on line proportional to work done for the line (for the next line?)
        on YIQ images, glitch happens at the same horizontal location (because YIQ work is constant length per line)
        on lines with no work at low clocks rates, perfect color lock.
        better at lower clocks, worse at higher clocks, so is there a glitch happening in the colorburst at higher clocks?  Earlier per frame?
        Almost EVERYTHING is in CCM RAM now, except for font.  Could maybe copy into CCM but getting tight on stack.
        Drawing lk.ppm, suddenly switches from red to green or green to blue, or about 90 degrees, implying one missed transfer.
            So the DMA couldn't get memory for N cycles?  Or the GPIO stalled long enough to miss?

Video modes
    80x24 text at 8x16 is 640x384
    80x24 text at 8x8 is 640x192
    underscan rects
        one rect is 196, 830, 44, 236 (shorter but wider) - PROBABLY CHOOSE THIS ONE
            to be /4, use 196, 828, 44, 236
            636 by 192, 122112 pixels in frame, 15264 bytes at 1-bit monochrome
                Apple 2 560x192 DHGR would fit in here
            318 double pixels wide, 61056 pixels in frame
            159 quad pixels wide, 30528 pixels in frame
        one rect is 209, 819, 40, 244 (slightly narrower but taller)
            to be /4, use 208, 820, 40, 244
            612 by 204, 124848 pixels in frame, 15606 bytes at 1-bit monochrome
                could get by with 512 x 200 in this mode
                Apple 2 560x192 DHGR would fit in here
            306 double pixels wide, 62424 pixels in frame
            153 quad pixels wide, 31212 pixels in frame 
        to get to 640 for 80x8 font, could do 196, 832, 44, 236
            height of font has to also be 8 at 192 pixels tall (matches Apple 2)
    overscan rect is 167, 862, 27, 257
        to be /4, 164, 864, 27, 257
        700 x 230, 20125 bytes at 1-bit monochome
        350 double pixels wide, 80500 pixels in frame, would need to be 4-bit
        175 quad pixels wide, 40250 pixels in frame, could support 8 bit

for reference, H is 63555.56us
Scope only locks to my video at line #5

221 capacitor is 220 pF / .22 nF
    3x = .66 nF
332 capacitor is 3300 pF / 3.3 nF
    So 1 nF or 2 nF might be nice intermediate
    2x would be 1.5 nF

Need database of video field formats
    VCR, Apple //e, Video tape, Look at Channel F output from VCR
    Want %H of each segment and voltage
        Number of first EQ burst (e.g. 0 or 6)
        Number of VSYNC bursts a la VCR and NTSC standard (e.g. 0 or 6)
        Number of VSYNC lines a la Apple //e (e.g. 4 or 0)
        Whether VSYNC lines have colorburst
        Number of second EQ burst (e.g. 0 or 6)
        Regular lines: sync pulse, back porch, location and count of colorbursts, front porch
        number of blank lines before, number of blank lines after
    "video {fcc1953, vcr, apple2e, tape, channelf}"

# Notes

So I now remember sort of that the Mikro has its own bootloader (?) which can only be used with the Mikro downloader EXE.  Does the Mikro not expose BOOT0?  I had made my own board out of an unmodified STM32 exposing BOOT0 on the crazy big protoboard.  I can downloading using "make burn", which calls dfu-util.

optimize Wolf Row more
    Measured taking between 86% and 92% of frame at 400 pixels
        at 200MHz I have HCLKs clocks per row.  Assume 10% on clearing pixels, 11488 HCLKs, so between 25 and 27 clocks per pixel; you're not going to get any faster.
    You should MIPmaps for quality but you're probably not thrashing cache, and that's going to slow you down.
    Maybe go to 2X pixels and 350 samples - can maybe MIPmap.

interlaced?  Does there need to be a non-interlaced vs interlaced mode?
    let VideoMode handle it in width, height, and aspect
    Then rowNumber to FillRow functions sequential line number?  so lineNumber = 262 is half the end of odd field, half the beginning of even field?
        240P modes would render lineNumber for odd field, lineNumber - 263 for even field
        480i modes would calculate lineNumber * 2 as rowNumber for even field, or (lineNumber 263) * 2 + 1 as rowNumber for odd field
        line 263 through 264 are handled specially by rowFill (copying in half of the next line)x
    implementation (starting from line 0)
        line 262 - overwrite last 405 samples with first 405 samples of EQ pulse
        lines 263, 264 - last 405 of eq pulse then first 405 of eq pulse
        lines 265 - last 405 of eq pulse then first 405 of vsync
        lines 266, 267 - last 405 of vsync then first 405 of vsync
        lines 268 - last 405 of vsync then first 405 of eq pulse
        lines 269, 270 - last 405 of eq pulse then first 405 of eq pulse
        line 271 - last 405 of eq pulse then 405 of SyncPorch
        special line 282 - write SyncPorch fron BackPorch to middle of line after mode's fillRow()
        fix all fillRows to handle row > 250

Why is there purple where there should be brown? -> palette setting failure?  Clamping in YIQ calculations?
    looks like a DAC issue - switch from 0x7F to 0x80 is a big voltage drop
    Assume this would get fixed with .1% tolerance resistors (or even 1% tolerance)

objdump - dump all sections:
    /Users/grantham/packages/gcc-arm-none-eabi-7-2018-q2-update/bin/arm-none-eabi-objdump -x main.elf
objdump - Sort regions 0x2000000 - 0x2000ffff by size (sort of, key not quite right)
    /Users/grantham/packages/gcc-arm-none-eabi-7-2018-q2-update/bin/arm-none-eabi-objdump -x main.elf | egrep ^2000 | sort -n -k 1.22,1.80

glitching appears no different if nothing is in CCM.  :(

NTSC was not stable with internal oscillator without correction - could not nail down correction

Should NTSC modes take an RGB and use some kind of optimized lookup of 4 pixels at a time?
    I couldn't figure out a way for this to be done in one scanline's time
    If DVDs really have 700 vertical lines resolution, what do they do when going to Composite?

What *are* the time bases for all TIM?  It seems like I can't get this right.
    the specs seem to point out correct behavior for TIMPRE.
    Also can verify the results in the CubeMX timing configurator.

Is the 746 actually running at 1/2 the clock I think it is?
    I don't think so
        now clocks.py DMA_BEATS output is correct
        the image is stable
        UART works
        SysClock output matches what I expect
        MCO2 outputting PLL / 5 yields 40MHz on the scope, which is 1/5 of 200 MHz

Does DMA fire on one edge or both?  Why do I have to /2 the TIM ARR for the 746?
    Because I had a higher divider for APB2, where TIM1 lives

speed issues - seems to be like 60%-80% speed of 415.  Should be 160% the speed of 415.
    ICache and DCache are disabled on boot
    ICache improves speed to more like what I expect.
    DCache causes video modes to fail.  UART still worked, so system booted and partially worked...  Need to look into the data cache.

enum Timer {
    TIM1 = 0, TIM2, TIM3, TIM4, TIM5, TIM6, TIM7, TIM8,
    TIM9, TIM10, TIM11, TIM12, TIM13, TIM14, TIM15,
};

int GetTIMxFrequency(Timer timer, int TIMPRE, int PPRE1, int PPRE2, int HCLKFrequency, int APB1Frequency, int APB2Frequency)
{
    int APBDomain;
    switch(timer) {
        case TIM2: case TIM3: case TIM4: case TIM5: case TIM6: case TIM7: case TIM12: case TIM13: case TIM14:
            APBDomain = 1; break;
        case TIM1: case TIM8: case TIM9: case TIM10: case TIM11: 
            APBDomain = 2; break;
    }

    int PPRE = (APBDomain == 1) ? PPRE1: PPRE2;
    int APBFrequency = (APBDomain == 1) ? APBFrequency1: APBFrequency2;

    if(TIMPRE == 0) {
        if(PPRE == 1) {
            return APBFrequency;
        } else {
            return APBFrequency * 2;
        }
    } else /* TIMPRE == 1 */ {
        if((PPRE == 1) || (PPRE == 2) || (PPRE == 4)) {
            return HCLKFrequency;
        } else {
            return APBFrequency * 4;
        }
    }
}

/* No faster than memcpy?  Because tight loop executes as fast as DMA? */
void MemoryCopyDMA(unsigned char* dst, unsigned char* src, size_t size)
{
    // XXX wait on previous DMA
    // Configure DMA to copy tmp row
    DMA2_Stream1->CR &= ~DMA_SxCR_EN;       /* disable DMA2_1 */
    DMA2->LIFCR = 0xF00;                        /* clear flags */
    DMA2_Stream1->NDTR = size / 4;
    DMA2_Stream1->PAR = (uint32_t)src;        // Source buffer address 0 in Memory-to-Memory mode
    DMA2_Stream1->M0AR = (uint32_t)dst;        // Dest buffer address in Memory-to-Memory mode
    DMA2_Stream1->FCR = DMA_FIFOMODE_ENABLE |   // Enable FIFO to improve stutter
        DMA_FIFO_THRESHOLD_FULL;        
    DMA2_Stream1->CR =
        DMA_CHANNEL_1 |                         
        DMA_MEMORY_TO_MEMORY |                  // Memory to Memory
        DMA_PDATAALIGN_WORD | // DMA_PBURST_INC4 |
        DMA_MDATAALIGN_WORD | // DMA_MBURST_INC4 |
        DMA_PRIORITY_LOW |
        DMA_PINC_ENABLE |                       // Increment memory address
        DMA_MINC_ENABLE |                       // Increment memory address
        0;
    DMA2_Stream1->CR |= DMA_SxCR_EN;    /* enable DMA */
} 


May 14: Strange bands of color May 14 is caused by DAC; verified
by running segtest monochrome with gradient 0 to 1

May 14: Weird aliasing that looks like I'm rendering at 1/4 res may
be caused by TV; verified by running segtest monochrome with gradient
0 to 1; grayscale images do not show bad aliasing.

May 22: C++
    * make_unique and unique_ptr work - verified within local block
    * #include <iostream> adds 200K to the executable - works, but avoid
    * exceptions work...!?
    * new and delete work, including try-catch bad_alloc
    * static constructed objects work
    * std::nothrow works - new returns 0
    * https://gist.github.com/bradgrantham/371f77dc2060fa4ad2fbe67940e4f7f6

README bits
Ever since I was very young, I've wanted to output video from a circuit I've built myself.  When I was a teenager, I bought a "TV modulator" module from Radio Shack.  With a minimum set of other components (mostly just power, if I remember correctly), it would turn composite NTSC video into broadcast VHF channel 3 or 4.

In the Alice 2, we built a very rudimentary NTSC circuit.  An UV-erasable EPROM provided the sync signals and a timer clocked out one bit pixels for video data.  It worked, but not very well.  17 years later, the circuit had degraded so that video output was badly broken and my attempts to redesign and upgrade the circuit fizzled.  We decided to abandon the old design and build the Alice 3 instead.

PIC OF ALICE 2 VIDEO BOARD AND IMAGE

In the Alice 3, we used a dedicated Propeller to output a textport to VGA frequencies from a Z80, and used an ARM to control peripherals including PS/2 keyboard and microSD.

PIC OF ALICE 3

But ARM microcontrollers these days have pretty advanced functionality and high clock rates.  NTSC is an old standard now, first supplanted by high clock rates and color resolutions in VGA, and later pure digital signals over HDMI and DisplayPort.  Still, the idea of building a complete "modern" "TV typewriter" with just an ARM and minimum parts seemed cool to me, so I built one.  I describe the design, capabilities, and limitations here.

# Color

Every NTSC scanline has a “colorburst” in the off-screen part of the line, at 3.579545 MHz.  This burst has the same *average* amplitude as the off-screen blank part of the line, and was much higher frequency than the usual pixel frequency, so B/W sets would just ignore it.

A color scanline was separated into luminance and chroma before transmission. A 3.579545MHz signal encoded the chroma with its phase (the hue; e.g. blue is 347 degrees, red is 103, green is 241) and its amplitude (saturation; 0 is gray, 1 is full color).  The luminance signal (0 to 1) and chroma (-1 to +1 scaled by the saturation) were added together for broadcast or composite cables.

Color TVs know to separate out the high-frequency component and turn that back into hue, saturation, and value (luminance or brightness).  B/W sets would not separate the high-frequency color signal so would just display the average signal so it would just show up as grayscale.

I think there’s some subtlety there to broadcast and where the signals lie in spectrum allocated to the channel.  I don’t understand radio, so I’ll just wave my hands.

Here’s a picture I’ve turned into NTSC video.  The green lines happen because I get a glitch sometimes in which causes the pixels are offset by some fraction of a 3.579545MHz wave, so the colors are all rotated around the color wheel.

PICTURE

# DAC

8 pins from a microcontroller are connected through resistors to form a (really bad) analog signal which I make slightly better with capacitors.

# Signal generation

I’m pretty sure a framebuffer from the 70's and 80's would turn RGB into YUV (“YIQ” for NTSC) and use logic to indicate when horizontal and digital sync signals should be.  Those would feed an analog circuit that would output a much higher quality analog signal.

I just drive the entire signal with DMA through the DAC
-----------------------

/Applications/STM32CubeIDE.app//Contents/Eclipse/plugins/com.st.stm32cube.ide.mcu.externaltools.cubeprogrammer.macos64_1.4.0.202007081208/tools/bin/STM32_Programmer_CLI -c port=SWD -w build/rosa.peripheral.test.hex
